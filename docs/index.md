## 统计学基础
### 统计学概述
#### 什么是统计学？
统计学是以数学为基础、以随机性为内核，以数据分析为体现的一门学科，主要通过利用概率论建立数学模型，收集所观察的数据，进行量化分析、总结，做出推断和预测，为相关决策提供依据和参考。

“数据是21世纪的石油”，我们每天每时每刻都会产生无数的数据，但这些数据在没有经过处理之前，只是一个个information，而不是knowledge。统计学就是把这些information收集起来，进行观察、量化分析，总结成knowledge的过程。一旦information变成knowledge了之后，我们就可以用所得到的知识规律去推断和预测未来。

《行为科学统计精要》一书对统计学的定义是：“统计学是一套组织、总结和解释信息的数学过程。” 作为一套数学工具，统计学可以拆分为两个部分，一个用于“整理总结数据”，另一个用于“解释信息”。

用于“整理总结数据”的统计方法被称为“描述统计学”，比如对于学生的数学期末考试成绩，我们可以通过计算平均分，用一个单一的数据就能了解这次考试的平均情况；通过计算标准差，我们可以了解学生考试成绩的集中趋势等等。

用于“解释信息”的统计方法被称为“推论统计学”，同样是数学期末考试的例子，假如为了提高教学质量，从全校某一年级学生中选出60个学生，分成两组，其中实验组A使用新的教学方法，控制组B使用原来的教学方法，一段时间后再次组织考试，然后我们得到两组学生的数学考试成绩，发现实验组学生的平均分比控制组的高，那么这种情况是偶然发生的？还是新的教学方法的确有效果？这个时候就需要使用推论统计学来进行评估了。

上面这个关于教学方法的实验，引出了统计学中的一个基础概念：总体和样本。

#### 总体和样本
总体表示的特定研究中所关注的所有个体的集合。对于有些研究来说，测量总体中所有的个体显然是不现实的。因此我们必须在研究中抽取出一定的样本来进行研究，这些样本被用来代表总体，我们需要从样本得出结论然后推广到总体。

对样本特征的描述被称为统计量，比如样本平均分，而对总体特征的描述被称为参数，比如总体平均分，它们是一一对应的，然而样本统计量与总体参数是不可能完全相等的，总会出现差异，这个差异被称为“抽样误差”。所以推论统计学就是用来回答“实验中观察到的差异，到底是抽样误差引起的，还是实验方法的确有显著效果”这一问题的数学工具。

#### 变量
不同个体会变化或者有不同值的特征就叫做“变量”。
变量有两类，一类是个体的某个具体特征，比如身高，体重和血型；另一类是会影响个体的外部因素，比如温度，湿度和天气情况。当然，也可以将变量分为离散变量和连续变量。进行实验就是对这些变量进行测量和观察，并得到数据集。有一些变量是可以直接测量和观察的，比如上面列举的这些，然而另外一些变量是抽象的，无法直接测量，比如我之前做过的用户优惠券敏感度，用户价值，用户购买力等，被称为“假设构建”（Constructs）。

我们可以通过观察和测量一些代表构建的外部行为来完成对假设构建的测量。这样的外部行为被称为“操作定义” （ Operational definitions ）。比如通过用户领取和使用优惠券的情况来衡量优惠券敏感度，通过用户已消费和预测未来消费来衡量用户价值等等。
 
#### 统计方法
系统地测量变量的过程，就称为“统计方法”。
如果我们需要测量每个个体两个非数值型变量之间的关系，我们可以用卡方检验。而如果是数值型变量之间的关系，那么我们可以使用“相关法”对其进行研究，最常见的就是绘制散点图来观察变化趋势。

但相关法的主要局限在于我们只能说明变量之间存在关联关系，但不能说明存在因果关系。其他数值型统计方法还包括假设检验，t检验和方差分析。要想说明因果关系，需要使用“实验法”，也就是我们常说的“AB test”。

如果我们想比较的是两组或多组的成绩，就要使用“实验法”和“非实验研究”。实验法可以建立两个变量之间的因果关系，它的特点在于“操纵和控制”，即操纵被试变量，并控制其他环境变量，降低其影响。比如将抑郁症病人随机分为两组，其中实验组的病人服用新药物，控制组的病人服用安慰剂，一段时间后观察病症改善状况，这个时候“服用新药物”还是“服用安慰剂”就是自变量，“症状改善的病人数量”就是因变量。

非实验研究与实验法的主要区别在于它仅仅观察，而不“操纵和控制”，常见的有非等效组研究和前后测研究。非等效组研究的一个例子比如以性别作为被试变量进行分组，因为性别是天生固有的性质，研究者并不是通过将实验对象分为两组，然后一组定义为女性，一组定义为男性来实现的，并没有“操纵和控制”，所以它不是实验研究；前后测研究常常与时间有关，比如对同一组病人测量治疗前后的康复情况，也属于非实验研究，理由同上。

#### 统计学小知识点
- **P value**

P值就是当原假设为真时所得到的样本观察结果或更极端结果出现的概率。如果P值很小，说明这种情况的发生的概率很小，而如果出现了，根据小概率原理，我们就有理由拒绝原假设，P值越小，我们拒绝原假设的理由越充分。
p值就是在原假设下，该总体出现现有数据的概率，或者说在现有数据下，原假设成立的一种合理性，p值越大，原假设成立的可能性就越大。p值越少，就说明原假设成立的可能性越小。通常当p值小于0.05时，就认为原假设不成立。

- **卡方检验**

卡方统计的公式： $\Sigma \cfrac{(f_O - f_e)^2}{f_e}$

公式中O代表observation，即实际频数；E代表Expectation，即期望频数。




## 数学基础

## 数据分析

## 机器学习
### 什么是机器学习
机器学习(Machine Learning，ML)是指从有限的观测数据中学习出具有一般性的规律，并利用这些规律对未知数据进行预测的方法.
传统的机器学习主要关注于如何学习一个预测模型. 一般需要首先将数据表示为一组特征(Feature)，特征的表示形式可以是连续的数值、离散的符号或其他形式. 然后将这些特征输入到预测模型，并输出预测结果. 这类机器学习可以看作是浅层学习(Shallow Learning). 浅层学习的一个重要特点是不涉及特征学习，其特征主要靠人工经验或特征转换方法来抽取. 

![Image](src)



(1) 数据预处理:经过数据的预处理，如去除噪声等. 比如在文本分类中，去除停用词等. 
(2) 特征提取:从原始数据中提取一些有效的特征. 比如在图像分类中，提取边缘、尺度不变特征变换(Scale Invariant Feature Transform，SIFT)特征等. 
(3)特征转换:对特征进行一定的加工，比如降维和升维. 降维包括特征抽取 (Feature Extraction)和特征选择(Feature Selection)两种途径. 常用的 特征转换方法有主成分分析(Principal Components Analysis，PCA)、线性判别分析(Linear Discriminant Analysis，LDA)等. 
(4) 预测:机器学习的核心部分，学习一个函数进行预测. 
2.2机器学习和深度学习的区别？
数据依赖：随着数据量的增加，二者的表现有很大区别。深度学习适合处理大数据，而数据量比较小的时候，用传统机器学习方法也许更合适。
硬件依赖：深度学习十分地依赖于高端的硬件设施，因为计算量实在太大了！深度学习中涉及很多的矩阵运算，因此很多深度学习都要求有GPU参与运算，因为GPU就是专门为矩阵运算而设计的。相反，普通的机器学习随便给一台破电脑就可以跑。
特征工程：在机器学习方法中，特征主要靠人工经验或特征转换方法来抽取 。然而深度学习算法试图自己从数据中学习特征。这也是深度学习十分引人注目的一点，毕竟特征工程是一项十分繁琐、耗费很多人力物力的工作，深度学习的出现大大减少了发现特征的成本。
运行时间：深度学习需要花大量的时间来训练，因为有太多的参数需要去学习。但是机器学习最多几小时就可以训练好。但是深度学习花费这么大力气训练处模型肯定不会白费力气的，优势就在于它模型一旦训练好，在预测任务上面就运行很快。这才能做到我们上面看到的视频中实时物体检测。
可理解性：深度学习很多时候我们难以理解，对我们现有的认知来说算是一个黑盒子。工作之后才发现，可解释性挺重要的。不管是业务人员，或是行业性质，都会要求你解释模型。不过现在已经有很多人在做神经网络可视化这种项目，我相信黑盒子也马上会变成白盒。
2.3无监督和有监督算法的区别？
无监督学习：是对没有标记的训练样本进行学习，以发现训练样本集中的结构性知识。因为所有标记都是未知的，所以训练样本的歧义性很高，也很难评价模型的效果。聚类就是典型的无监督学习。（Kmeans, DBSCAN, PCA) （组间差异最大化，组内差异最小化）
有监督学习：是对已有标记的训练样本进行学习，来尽可能对训练样本集外的数据进行标记预测。因为所有样本标记都是已知的，所以歧义性低。像逻辑回归、GBDT、随机森林等都是有监督学习。
PCA：主成分分析(Principal Component Analysis，PCA)
是一种最常用的数据降维方法，使得在转换后的空间中数据的方差最大. 选择数据方差最大的方向进行投影，才能最大化数据的差异性，保留更多的原始数据信息. 
LR 的简介和特性，损失函数？
简介
逻辑回归（Logistic Regression）是一种用于解决二分类（0 or 1）问题的机器学习方法，用于估计某种事物的可能性。比如我之前做过的用户7日内会发生购买可能性，以及某广告被用户点击的可能性等。 
逻辑回归（Logistic Regression）与线性回归（Linear Regression）都是一种广义线性模型（generalized linear model）。逻辑回归假设因变量 y 服从伯努利分布，而线性回归假设因变量 y 服从高斯分布。 因此与线性回归有很多相同之处，去除Sigmoid映射函数的话，逻辑回归算法就是一个线性回归。可以说，逻辑回归是以线性回归为理论支持的，但是逻辑回归通过Sigmoid函数引入了非线性因素，因此可以轻松处理0/1分类问题。

逻辑回归的假设函数形式如下：

决策边界  是一个方程，用于标识出分类函数（模型）的分类边界，可以是线性或者非线形的。

 在逻辑回归中，最常用的是代价函数是交叉熵(Cross Entropy)，交叉熵是一个常见的代价函数，在神经网络中也会用到。


优点：实现简单，计算量小，速度快，存储资源低。
缺点：因为模型简单，在复杂的情况下会出现欠拟合，并且只能处理二分类问题。
3. SVM的简介和特性？多分类怎么处理？
Support Vector Machine。SVM模型是将实例表示为高维空间中的点，然后我们要找出那个以最大间隔将不同标记的样本分开的超平面。然后，将新的实例映射到同一空间，并基于它们落在间隔的哪一侧来预测所属类别。但用于区分的集合在原有高维空间中往往线性不可分。为此，我们可以加入kernel来将原有限维空间映射到维数高得多的空间中，在该空间中进行分离可能会更容易，也就是引入非线性分类。
常见的核函数包括：
多项式：比线性核拟合程度更强，知道具体维度，但是高次容易出现数值不稳定，参数选择较多。
高斯径向基函数：拟合能力最强，但是要注意过拟合问题。只有一个参数需要调整。
双曲正切：
SVM的有效性取决于核函数、核参数和软间隔参数 C 的选择。 通常会选只有一个参数lambda的高斯核。C 和lambda 的最佳组合通常通过在 C 和 lambda 为指数增长序列下网格搜索来选取。
特性：简单、速度快。

多元分类支持向量机：SVM算法最初是为二值分类问题设计的，实现多分类的主要方法是将一个多分类问题转化为多个二分类问题。常见方法包括“一对一”、“一对多”和“多对多”。
一对一：将N个类别两两配对，产生N(N-1)/2 个二分类任务，测试阶段新样本同时交给所有的分类器，最终结果通过投票产生。
一对多：是将某个类别的样本作为正例,其他剩余的样本归为负例，这样N个类别的样本就构造出了N个二分类SVM。测试时如果只有一个分类器预测为正，则对应类别为最终结果；如果有多个，则一般选择置信度最大的。虽然从分类器角度一对一会产生更多的分类器，但每一次只用了2个类别，因此当类别数很多的时候一对一开销通常更小。
多对多：若干类作为正类，若干类作为反类。正反类必须特殊设计。
SVM如何用于回归？
硬间隔、软间隔？






## 深度学习






### Markdown

Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for

```markdown
Syntax highlighted code block

# Header 1
## Header 2
### Header 3

- Bulleted
- List

1. Numbered
2. List

**Bold** and _Italic_ and `Code` text

[Link](url) and ![Image](src)
```

For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).

### Jekyll Themes

Your Pages site will use the layout and styles from the Jekyll theme you have selected in your [repository settings](https://github.com/TU-Dan/TU-Dan.github.io/settings/pages). The name of this theme is saved in the Jekyll `_config.yml` configuration file.

### Support or Contact

Having trouble with Pages? Check out our [documentation](https://docs.github.com/categories/github-pages-basics/) or [contact support](https://support.github.com/contact) and we’ll help you sort it out.
